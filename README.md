# BadmintonNetTouch

バドミントン ネットプレー自動判定システム (BadmintonNetTouch)
1. 概要
このプロジェクトは、バドミントンの試合映像と慣性センサーのデータを活用し、「ネットタッチ」や「オーバーネット」といったネット際の反則を自動で検出・判定することを目的とした、卒業研究プロジェクトです。

開発は主にGoogle Colab上で行われ、コンピュータビジョンとセンサーデータ分析、機械学習の手法を組み合わせて判定システムのプロトタイプを構築します。

2. 主な機能
本リポジトリには、研究開発を効率化するための以下のツールやスクリプト（のロジック）が含まれています。

重要フレーム自動抽出機能: 動画の中から、AI（MediaPipe）が「ラケットがネットに近づいた」と判断した、解析すべき重要なフレームだけを自動で画像として切り出します。

対話型ラベリング機能: 抽出された画像に対し、Colabノートブック上でボタンをクリックするだけで、「ネットタッチ」「オーバーネット」「正常」といったラベルを高速に付与できます。

データセット自動分割機能: ラベル付けしたデータを、機械学習に必要な「学習用(train)」「検証用(validation)」「テスト用(test)」に、指定した比率で自動的に振り分けます。

AIモデル学習機能: 準備したデータセットを使い、転移学習やデータ拡張といった技術を取り入れた高精度な画像分類モデルを学習させます。

センサーデータ分析機能: iPhoneで記録したセンサーデータ（加速度・角速度）を読み込み、グラフ化して衝撃（インパクト）を検出するロジックをテストします。

3. 開発ワークフロー
本プロジェクトは、以下のクラウドサービスを連携させた、モダンな開発ワークフローを採用しています。

Google Colab: メインの開発・実行環境。高性能なGPUを無料で利用できます。

Google Drive: 大容量の動画データ、画像データセット、学習済みモデルなどを保管するデータストレージ。

GitHub: すべてのコード（.ipynbノートブックなど）を管理するバージョン管理システム。

4. 環境構築と使い方
このプロジェクトを再現・実行するには、以下の手順に従います。

ステップ1：準備
このGitHubリポジトリを、ご自身のPCにgit cloneします。

Google Driveに研究用のフォルダ（例: Badminton_Research）を作成し、その中にvideos, datasets, modelsといったサブフォルダを作成します。

解析したい動画をvideosフォルダに、AIモデルファイル（efficientdet_lite0.tfliteなど）をmodelsフォルダにアップロードします。

ステップ2：Colabでの実行
Google Colabを開き、「ファイル」メニュー → 「ノートブックを開く」を選択します。

GitHubタブを選び、このリポジトリのURLを入力して、メインのノートブック（main_workflow.ipynbなど）を開きます。

ノートブックの最初のセルを実行し、Google Driveをマウントします。

Python

from google.colab import drive
drive.mount('/content/drive')
次のセルで、必要なライブラリをインストールします。

Python

!pip install "numpy<2.0" mediapipe==0.10.9 ultralytics torch
以降は、ノートブックの各セル（フレーム抽出、ラベリングなど）を上から順番に実行していきます。

5. 使用技術スタック
言語: Python

メイン環境: Google Colaboratory

主要ライブラリ:

AI / 機械学習: TensorFlow, Keras, Scipy

コンピュータビジョン: OpenCV, MediaPipe, Ultralytics (YOLOv8)

データ操作: Pandas, NumPy

センサー: WT9011DCL (データ収集)
